{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalisys-Train-BoW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_nQixLUYpPf"
      },
      "source": [
        "# Collect the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NxnqJsbbgX5"
      },
      "source": [
        "We use, for example, the dataset present in the article, but if you want to train a model in your dataset, you must use your dataset. Or, if you're going to use the dataset present in the article with another model, you only must change the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gdX0jFkYyF9",
        "outputId": "86ab95a4-d71a-42ee-81d1-27d67e64c62f"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/adailtonaraujo/app_review_analysis/master/Sentiment/Datasets/Dataset_Sentiment_BoW.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-08 00:39:14--  https://raw.githubusercontent.com/adailtonaraujo/app_review_analysis/master/Sentiment/Datasets/Dataset_Sentiment_BoW.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180750 (177K) [text/plain]\n",
            "Saving to: ‘Dataset_Sentiment_BoW.csv’\n",
            "\n",
            "\r          Dataset_S   0%[                    ]       0  --.-KB/s               \rDataset_Sentiment_B 100%[===================>] 176.51K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-05-08 00:39:14 (16.0 MB/s) - ‘Dataset_Sentiment_BoW.csv’ saved [180750/180750]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKHt1vhzyiwF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b78cbd6e-89e0-4b7f-9f79-ca8381e9f49e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_complete = pd.read_csv(\"Dataset_Sentiment_BoW.csv\")\n",
        "df_complete[df_complete['class']=='Negative']"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>feature</th>\n",
              "      <th>appName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Too many ads and secondly erratic interface</td>\n",
              "      <td>Negative</td>\n",
              "      <td>interface</td>\n",
              "      <td>PhotoEditor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>There are so many ads popping up that the app ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>ad pops up</td>\n",
              "      <td>PhotoEditor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Horrible editor, worst app in this entire store</td>\n",
              "      <td>Negative</td>\n",
              "      <td>editor</td>\n",
              "      <td>PhotoEditor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>I gave this app a 5 stars cause rate me pls al...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>rate me pls always pops out</td>\n",
              "      <td>PhotoEditor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Have to download everything and adverts are an...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>adverts</td>\n",
              "      <td>PhotoEditor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391</th>\n",
              "      <td>It doesnt let you pick the song u want to list...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>shuffle</td>\n",
              "      <td>Spotify</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1413</th>\n",
              "      <td>Only problem I have with the app is the inabil...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>download music to an SD card</td>\n",
              "      <td>Spotify</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1420</th>\n",
              "      <td>Cmon everythings on shuffle, random music pops...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>shuffle</td>\n",
              "      <td>Spotify</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1421</th>\n",
              "      <td>Cmon everythings on shuffle, random music pops...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>random music pops up</td>\n",
              "      <td>Spotify</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1422</th>\n",
              "      <td>Cmon everythings on shuffle, random music pops...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>ads</td>\n",
              "      <td>Spotify</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>136 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ...      appName\n",
              "3          Too many ads and secondly erratic interface   ...  PhotoEditor\n",
              "24    There are so many ads popping up that the app ...  ...  PhotoEditor\n",
              "32     Horrible editor, worst app in this entire store   ...  PhotoEditor\n",
              "38    I gave this app a 5 stars cause rate me pls al...  ...  PhotoEditor\n",
              "50    Have to download everything and adverts are an...  ...  PhotoEditor\n",
              "...                                                 ...  ...          ...\n",
              "1391  It doesnt let you pick the song u want to list...  ...      Spotify\n",
              "1413  Only problem I have with the app is the inabil...  ...      Spotify\n",
              "1420  Cmon everythings on shuffle, random music pops...  ...      Spotify\n",
              "1421  Cmon everythings on shuffle, random music pops...  ...      Spotify\n",
              "1422  Cmon everythings on shuffle, random music pops...  ...      Spotify\n",
              "\n",
              "[136 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t2gPMCReutA",
        "outputId": "580986b5-2cc7-4368-9202-9a7482a5cef7"
      },
      "source": [
        "appList=classes=list(df_complete['appName'].unique())\n",
        "appList"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PhotoEditor',\n",
              " 'Evernote',\n",
              " 'eBay',\n",
              " 'WhatsApp',\n",
              " 'Netflix',\n",
              " 'Twitter',\n",
              " 'Facebook',\n",
              " 'Spotify']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqB6O_NAe4DM",
        "outputId": "e7bbb98b-8ea5-4eab-92f2-5f37d262a839"
      },
      "source": [
        "classes=list(df_complete['class'].unique())\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Neutral', 'Negative', 'Positive']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNX0xE2rwWxP"
      },
      "source": [
        "# Bag-of-Words\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7-vb0N8yJjZ"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F9q0KfNwx4J",
        "outputId": "db07dfed-eac4-4b75-f5dd-72a67956772f"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "nltk.download('stopwords') \n",
        "nltk.download('punkt') \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrQ1UK9EyWQM"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HTcnRSlgHJn"
      },
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english') \n",
        "  \n",
        "def tokenize(text):\n",
        "  \n",
        "  p = re.compile('\\d')\n",
        "\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "\n",
        "  stems  = []\n",
        "  for item in tokens:\n",
        "    if len(item) > 2 and not p.match(item):  \n",
        "      stems.append(SnowballStemmer(\"english\").stem(item))\n",
        "  return stems"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0yyYAa4YzDT"
      },
      "source": [
        "# functions to Train the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjeMtuov20T_"
      },
      "source": [
        "## import models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdJBZW_122c9"
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "from sklearn.neural_network import MLPClassifier as MLP\n",
        "from sklearn.naive_bayes import GaussianNB as NB\n",
        "from sklearn.naive_bayes import MultinomialNB as MNB\n",
        "from sklearn.svm import SVC as SVM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPc3-yTs2_MA"
      },
      "source": [
        "if you use the KNN its interessant use the metric cosine that is good for text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ND6GAr3IIJ"
      },
      "source": [
        "def cosseno(x,y):\n",
        "  dist = cosine(x,y)\n",
        "  if np.isnan(dist):\n",
        "   return 1\n",
        "  return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaRLh2IQ3RLh"
      },
      "source": [
        "## Algorithms Variation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9FpliHL3_go"
      },
      "source": [
        "You can change the algorithms parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8vQTfmB3QBA"
      },
      "source": [
        "algs = {\n",
        "    \"KNN\" : KNN(metric=cosseno),\n",
        "    \"MLP\" : MLP(),\n",
        "    \"NB\" : NB(),\n",
        "    \"MNB\" : MNB(alpha=0.4, fit_prior=False),\n",
        "    \"SVM\" : SVM()\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogWOQA2Www_n"
      },
      "source": [
        "#Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_H_4q1iw5i6",
        "outputId": "49ece857-220f-458a-81c0-8622980a3828"
      },
      "source": [
        "#Matrix TF-IDF\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words=stop_words, ngram_range=(1,1))\n",
        "Mtfidf = tfidf.fit_transform(df_complete['text'])\n",
        "vocab_apps=tfidf.vocabulary_ # Vocabulary with the position of each term in the matrix\n",
        "tfidf=Mtfidf.toarray() # TF-IDF term weight matrix\n",
        "\n",
        "#Adjusting weight of tokens that are aspectocs in TF-IDF arrays\n",
        "# Strategy: tokem who is aspcto = original TF-IDF + max (TF-IDF of the document's tokens)\n",
        "\n",
        "for index, row in df_complete.iterrows():\n",
        "  feature_list=tokenize(row[2]) #tokeniza\n",
        "  feature_list=[w for w in feature_list if not w in stop_words] #remove stopwords\n",
        "  max_document=max(tfidf[index])\n",
        "  for i in range(0,len(feature_list)):\n",
        "    if feature_list[i]=='phptp': continue #only 1 occurrence where the token was not for vocabulary and treatment in the feature did not eliminate\n",
        "    pos_feature=vocab_apps[feature_list[i]] # get the position of the aspect token in BoW \n",
        "    tfidf[index][pos_feature]=tfidf[index][pos_feature]+max_document\n",
        "tfidf.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'might', 'must', \"n't\", 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'veri', 'whi', 'would', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1429, 1462)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzUw5at0xkPG"
      },
      "source": [
        "#Grouping the data by app\n",
        "train_label_apps={}\n",
        "test_label_apps={}\n",
        "\n",
        "train_tfidf_apps={}\n",
        "test_tfidf_apps={}\n",
        "\n",
        "for app in appList:\n",
        "  train_label_apps[app]=list()\n",
        "  test_label_apps[app]=list()\n",
        "  train_tfidf_apps[app]=list()\n",
        "  test_tfidf_apps[app]=list()\n",
        "  \n",
        "for app in appList:\n",
        "  for index, row in df_complete.iterrows():\n",
        "    if row[3]!=app: #Train (except tested app)\n",
        "      train_tfidf_apps[app].append(tfidf[index])\n",
        "      train_label_apps[app].append(row[1])\n",
        "    if row[3]==app: #Test \n",
        "      test_tfidf_apps[app].append(tfidf[index])\n",
        "      test_label_apps[app].append(row[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmSBKaJh4J_V"
      },
      "source": [
        "## Define the algorithm that you will use and the app test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlNqAcFBZKMp"
      },
      "source": [
        "clf = algs['MLP']\n",
        "appTest = 'Spotify'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am_FWlsu4Ybx"
      },
      "source": [
        "## Train-Test division"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRk_-LIxeXGp"
      },
      "source": [
        "First, you must define the train and the test set. *test_size* define the percent of examples of test set, consequently, the train set size is 1 - *test_size*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeNgKAIJyjX-"
      },
      "source": [
        "x_train = train_tfidf_apps[appTest]\n",
        "y_train_class=train_label_apps[appTest]\n",
        "\n",
        "x_test = test_tfidf_apps[appTest]\n",
        "y_test_class=test_label_apps[appTest]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA7uzEHd431r"
      },
      "source": [
        "# Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrdHGCwR5Vpz"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO5Vb881dndy",
        "outputId": "7951643a-7164-4d4f-de04-fe287813af63"
      },
      "source": [
        "clf.fit(x_train,y_train_class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iKPkmam5cNK"
      },
      "source": [
        "### Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJfzvMw3iRYH"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pkl_filename = \"pickle_MLP_Spotify.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(clf, file) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMtAWpRFia9s"
      },
      "source": [
        "if you want to load the model, use:\n",
        "\n",
        "with open(pkl_filename, 'rb') as file: \\\\\n",
        "    clf = pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sy9D_gdeTUm"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVe9kmaDi8fY"
      },
      "source": [
        "y_pred = clf.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb9cmP5Ns7xh",
        "outputId": "469aab2c-09e6-477e-f4af-eadccada8e50"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test_class, y_pred, output_dict=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.36      0.20      0.26        25\n",
            "     Neutral       0.79      0.78      0.78       120\n",
            "    Positive       0.49      0.71      0.58        31\n",
            "\n",
            "    accuracy                           0.68       176\n",
            "   macro avg       0.55      0.56      0.54       176\n",
            "weighted avg       0.68      0.68      0.67       176\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM8PUukpCISB"
      },
      "source": [
        "# Case Study"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F7T6ELaCXFA"
      },
      "source": [
        "texts = ['Horrible editor, worst app in this entire store','Too many ads and secondly erratic interface', 'I loved this app!!']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEJ-aV8MCOql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999290b7-6e70-49f1-d0a6-c69fb47be62f"
      },
      "source": [
        "vectorizer = TfidfVectorizer(tokenizer=tokenize, stop_words=stop_words, ngram_range=(1,1))\n",
        "vectorizer.fit(df_complete['text'])\n",
        "def Classification(text):\n",
        "  bow_test = vectorizer.transform([text]).toarray()\n",
        "  resp = clf.predict(bow_test)\n",
        "  print('The text: \"' + text + '\" belongs to the '+ str(resp[0]).upper() +' class' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'might', 'must', \"n't\", 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'veri', 'whi', 'would', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX0F0gkjCVb7",
        "outputId": "1fd37a7e-1d81-4765-aa88-1042836d0ba7"
      },
      "source": [
        "for text in texts:\n",
        "  Classification(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The text: \"Horrible editor, worst app in this entire store\" belongs to the NEGATIVE class\n",
            "The text: \"Too many ads and secondly erratic interface\" belongs to the NEUTRAL class\n",
            "The text: \"I loved this app!!\" belongs to the POSITIVE class\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}